# AI-Powered Customer Feedback Analysis System

A comprehensive system for analyzing customer feedback using advanced AI and machine learning techniques. This project provides automated sentiment analysis, topic modeling, and feedback categorization capabilities through a RESTful API interface.

## Table of Contents

- [Features](#features)
- [Architecture](#architecture)
- [Installation](#installation)
- [Configuration](#configuration)
- [Usage](#usage)
- [API Documentation](#api-documentation)
- [Machine Learning Models](#machine-learning-models)
- [Docker Deployment](#docker-deployment)
- [Development](#development)
- [Testing](#testing)
- [Contributing](#contributing)
- [License](#license)

## Features

### Core Capabilities

**Sentiment Analysis**
- Multi-approach sentiment analysis using lexicon-based (VADER) and machine learning models
- Support for ensemble methods combining multiple approaches
- Confidence scoring and detailed sentiment breakdowns
- Batch processing capabilities for large datasets

**Topic Modeling**
- Multiple topic modeling algorithms: Latent Dirichlet Allocation (LDA), Non-negative Matrix Factorization (NMF), and K-means clustering
- Automatic topic labeling and keyword extraction
- Configurable number of topics and model parameters
- Topic distribution analysis and visualization support

**Feedback Categorization**
- Rule-based categorization using keyword matching
- Machine learning-based categorization with multiple algorithms
- Ensemble approach combining rule-based and ML methods
- Predefined categories: Product Quality, Customer Service, Pricing, Delivery/Shipping, Website/UI, General
- Custom category support with keyword management

**Data Processing**
- Comprehensive text preprocessing pipeline
- Support for multiple input formats (CSV, JSON, plain text)
- Data validation and quality checks
- Feature extraction and text statistics
- Batch processing and real-time analysis

**API Interface**
- RESTful API with comprehensive endpoints
- Feedback submission and retrieval
- Batch processing capabilities
- Export functionality (JSON, CSV formats)
- Health monitoring and statistics
- CORS support for web applications

## Architecture

The system follows a modular architecture with clear separation of concerns:

```
AI-Powered-Customer-Feedback-Analysis-System/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ api.py                 # Flask API endpoints
â”‚   â”œâ”€â”€ data_ingestion.py      # Data ingestion and validation
â”‚   â”œâ”€â”€ preprocessing.py       # Text preprocessing pipeline
â”‚   â”œâ”€â”€ sentiment_analysis.py  # Sentiment analysis models
â”‚   â”œâ”€â”€ topic_modeling.py      # Topic modeling algorithms
â”‚   â””â”€â”€ categorization.py      # Feedback categorization
â”œâ”€â”€ config.ini                 # Configuration settings
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ Dockerfile                 # Container configuration
â”œâ”€â”€ docker-compose.yml         # Multi-service deployment
â”œâ”€â”€ .env.example              # Environment variables template
â”œâ”€â”€ .gitignore                # Git ignore rules
â””â”€â”€ README.md                 # Project documentation
```

### Component Overview

**Data Ingestion Module** (`data_ingestion.py`)
Handles the ingestion of customer feedback from various sources including CSV files, JSON files, and direct API submissions. Provides data validation, format standardization, and batch processing capabilities.

**Preprocessing Module** (`preprocessing.py`)
Implements a comprehensive text preprocessing pipeline including text cleaning, normalization, tokenization, stopword removal, stemming, and lemmatization. Extracts various text features for analysis.

**Sentiment Analysis Module** (`sentiment_analysis.py`)
Provides multiple approaches to sentiment analysis including lexicon-based methods using VADER and machine learning models. Supports ensemble methods and confidence scoring.

**Topic Modeling Module** (`topic_modeling.py`)
Implements various topic modeling algorithms including LDA, NMF, and K-means clustering. Provides topic extraction, labeling, and keyword analysis capabilities.

**Categorization Module** (`categorization.py`)
Offers both rule-based and machine learning approaches to feedback categorization. Includes predefined categories and supports custom category management.

**API Module** (`api.py`)
Implements a comprehensive RESTful API using Flask with endpoints for feedback submission, analysis, retrieval, and export. Includes health monitoring and statistics.

## Installation

### Prerequisites

- Python 3.11 or higher
- pip package manager
- Git (for cloning the repository)
- Docker and Docker Compose (for containerized deployment)

### Local Installation

1. **Clone the repository**
```bash
git clone https://github.com/yourusername/AI-Powered-Customer-Feedback-Analysis-System.git
cd AI-Powered-Customer-Feedback-Analysis-System
```

2. **Create a virtual environment**
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. **Install dependencies**
```bash
pip install -r requirements.txt
```

4. **Download NLTK data**
```bash
python -c "import nltk; nltk.download('punkt'); nltk.download('stopwords'); nltk.download('wordnet'); nltk.download('vader_lexicon'); nltk.download('averaged_perceptron_tagger'); nltk.download('maxent_ne_chunker'); nltk.download('words')"
```

5. **Create necessary directories**
```bash
mkdir -p logs models exports data
```

6. **Configure the application**
```bash
cp .env.example .env
# Edit .env file with your configuration
```

### Docker Installation

1. **Clone the repository**
```bash
git clone https://github.com/yourusername/AI-Powered-Customer-Feedback-Analysis-System.git
cd AI-Powered-Customer-Feedback-Analysis-System
```

2. **Build and run with Docker Compose**
```bash
docker-compose up -d
```

The application will be available at `http://localhost:5000`.

## Configuration

The system uses a configuration file (`config.ini`) and environment variables for settings management.

### Configuration File Structure

The `config.ini` file contains the following sections:

- **API**: API server configuration (host, port, CORS settings)
- **DATABASE**: Database connection settings (for future implementation)
- **MODELS**: Machine learning model configuration
- **PREPROCESSING**: Text preprocessing parameters
- **SENTIMENT_ANALYSIS**: Sentiment analysis settings
- **TOPIC_MODELING**: Topic modeling parameters
- **CATEGORIZATION**: Categorization configuration
- **LOGGING**: Logging configuration
- **SECURITY**: Security and rate limiting settings
- **PERFORMANCE**: Performance optimization settings
- **EXPORT**: Data export configuration
- **MONITORING**: System monitoring settings

### Environment Variables

Key environment variables (see `.env.example` for complete list):

- `FLASK_ENV`: Flask environment (development/production)
- `API_HOST`: API server host (default: 0.0.0.0)
- `API_PORT`: API server port (default: 5000)
- `LOG_LEVEL`: Logging level (INFO, DEBUG, WARNING, ERROR)
- `MODEL_CACHE_DIR`: Directory for storing trained models

## Usage

### Starting the Application

**Local Development**
```bash
python src/api.py
```

**Docker**
```bash
docker-compose up
```

The API will be available at `http://localhost:5000`.

### Basic Usage Examples

**Submit Single Feedback**
```bash
curl -X POST http://localhost:5000/feedback/submit \
  -H "Content-Type: application/json" \
  -d '{
    "feedback_text": "Great product! I love the quality and design.",
    "rating": 5,
    "customer_id": "customer_001"
  }'
```

**Submit Batch Feedback**
```bash
curl -X POST http://localhost:5000/feedback/batch \
  -H "Content-Type: application/json" \
  -d '{
    "feedback_list": [
      {
        "feedback_text": "Excellent service!",
        "rating": 5
      },
      {
        "feedback_text": "Poor quality product.",
        "rating": 2
      }
    ]
  }'
```

**Preprocess Feedback**
```bash
curl -X POST http://localhost:5000/feedback/preprocess \
  -H "Content-Type: application/json" \
  -d '{
    "steps": ["clean", "remove_stopwords", "lemmatize"]
  }'
```

**Get System Statistics**
```bash
curl http://localhost:5000/stats
```

### Python API Usage

```python
from src.data_ingestion import FeedbackDataIngestion
from src.preprocessing import FeedbackPreprocessor
from src.sentiment_analysis import SentimentAnalyzer
from src.topic_modeling import TopicModeler
from src.categorization import FeedbackCategorizer

# Initialize components
ingestion = FeedbackDataIngestion()
preprocessor = FeedbackPreprocessor()
sentiment_analyzer = SentimentAnalyzer(model_type='ensemble')
topic_modeler = TopicModeler(n_topics=5)
categorizer = FeedbackCategorizer()

# Load and preprocess data
df = ingestion.ingest_csv('feedback_data.csv', 'feedback_text', 'rating')
df_processed = preprocessor.preprocess_dataframe(df)

# Analyze sentiment
df_sentiment = sentiment_analyzer.analyze_dataframe(df_processed)

# Extract topics
topic_results = topic_modeler.fit_all_models(df_processed['feedback_text'].tolist())

# Categorize feedback
df_categorized = categorizer.analyze_dataframe(df_processed)
```



## API Documentation

The system provides a comprehensive RESTful API for feedback analysis. All endpoints return JSON responses and support CORS for web applications.

### Base URL
```
http://localhost:5000
```

### Endpoints

#### Health Check
**GET** `/health`

Check the health status of the API.

**Response:**
```json
{
  "status": "healthy",
  "timestamp": "2024-01-15T10:30:00.000Z",
  "version": "1.0.0"
}
```

#### Submit Feedback
**POST** `/feedback/submit`

Submit a single feedback entry for analysis.

**Request Body:**
```json
{
  "feedback_text": "Great product! I love the quality and design.",
  "rating": 5,
  "customer_id": "customer_001",
  "product_id": "product_123",
  "metadata": {
    "source": "website",
    "page": "product_page"
  }
}
```

**Response:**
```json
{
  "message": "Feedback submitted successfully",
  "feedback_id": 1,
  "status": "submitted"
}
```

#### Submit Batch Feedback
**POST** `/feedback/batch`

Submit multiple feedback entries at once.

**Request Body:**
```json
{
  "feedback_list": [
    {
      "feedback_text": "Excellent service!",
      "rating": 5,
      "customer_id": "customer_001"
    },
    {
      "feedback_text": "Poor quality product.",
      "rating": 2,
      "customer_id": "customer_002"
    }
  ]
}
```

**Response:**
```json
{
  "message": "Batch submission completed",
  "submitted_count": 2,
  "submitted_ids": [1, 2],
  "error_count": 0,
  "errors": []
}
```

#### List Feedback
**GET** `/feedback/list`

Retrieve a list of submitted feedback with optional filtering.

**Query Parameters:**
- `limit` (int): Maximum number of results (default: 100)
- `offset` (int): Number of results to skip (default: 0)
- `status` (string): Filter by status (submitted, processed, etc.)
- `customer_id` (string): Filter by customer ID
- `product_id` (string): Filter by product ID

**Response:**
```json
{
  "feedback": [
    {
      "id": 1,
      "feedback_text": "Great product!",
      "rating": 5,
      "customer_id": "customer_001",
      "timestamp": "2024-01-15T10:30:00.000Z",
      "status": "submitted"
    }
  ],
  "total_count": 1,
  "limit": 100,
  "offset": 0,
  "has_more": false
}
```

#### Get Specific Feedback
**GET** `/feedback/{feedback_id}`

Retrieve a specific feedback entry by ID.

**Response:**
```json
{
  "id": 1,
  "feedback_text": "Great product!",
  "rating": 5,
  "customer_id": "customer_001",
  "product_id": "product_123",
  "metadata": {},
  "timestamp": "2024-01-15T10:30:00.000Z",
  "status": "submitted"
}
```

#### Preprocess Feedback
**POST** `/feedback/preprocess`

Preprocess submitted feedback data.

**Request Body:**
```json
{
  "feedback_ids": [1, 2, 3],
  "steps": ["clean", "remove_stopwords", "lemmatize"]
}
```

**Response:**
```json
{
  "message": "Preprocessing completed successfully",
  "processed_count": 3,
  "summary": {
    "original_count": 3,
    "processed_count": 3,
    "removed_count": 0,
    "original_avg_length": 45.2,
    "processed_avg_length": 32.1
  }
}
```

#### Export Feedback
**GET** `/feedback/export`

Export feedback data in various formats.

**Query Parameters:**
- `format` (string): Export format (json, csv) - default: json
- `include_processed` (boolean): Include processed text - default: false

**Response:**
For JSON format:
```json
{
  "export_timestamp": "2024-01-15T10:30:00.000Z",
  "total_records": 10,
  "data": [...]
}
```

For CSV format: Returns CSV file download.

#### Get Statistics
**GET** `/stats`

Get system statistics and analytics.

**Response:**
```json
{
  "total_feedback": 100,
  "status_distribution": {
    "submitted": 60,
    "processed": 40
  },
  "rating_distribution": {
    "1": 5,
    "2": 10,
    "3": 20,
    "4": 30,
    "5": 35
  },
  "average_rating": 3.8,
  "average_text_length": 42.5,
  "latest_submission": "2024-01-15T10:30:00.000Z"
}
```

### Error Responses

All endpoints return appropriate HTTP status codes and error messages:

**400 Bad Request:**
```json
{
  "error": "feedback_text is required"
}
```

**404 Not Found:**
```json
{
  "error": "Feedback not found"
}
```

**500 Internal Server Error:**
```json
{
  "error": "Internal server error"
}
```

## Machine Learning Models

The system implements multiple machine learning approaches for feedback analysis, providing flexibility and accuracy through ensemble methods.

### Sentiment Analysis Models

#### Lexicon-Based Analysis (VADER)
The VADER (Valence Aware Dictionary and sEntiment Reasoner) sentiment analysis tool is specifically attuned to social media text and provides:
- Compound sentiment scores ranging from -1 (most negative) to +1 (most positive)
- Individual scores for positive, negative, and neutral sentiment
- Handling of punctuation, capitalization, and emoticons
- Real-time analysis without training requirements

**Usage:**
```python
analyzer = SentimentAnalyzer(model_type='lexicon')
result = analyzer.analyze_sentiment_lexicon("Great product!")
# Returns: {'sentiment': 'positive', 'confidence': 0.6588, 'scores': {...}}
```

#### Machine Learning Models
The system supports multiple ML algorithms for sentiment classification:

**Logistic Regression**
- Linear model with regularization
- Fast training and prediction
- Good interpretability
- Suitable for large datasets

**Naive Bayes (Multinomial)**
- Probabilistic classifier
- Works well with text data
- Handles class imbalance effectively
- Fast training and prediction

**Support Vector Machine (SVM)**
- Effective for high-dimensional data
- Good generalization performance
- Supports probability estimates
- Robust to overfitting

**Random Forest**
- Ensemble of decision trees
- Handles feature interactions
- Provides feature importance
- Robust to noise and outliers

**Model Training Process:**
1. Text preprocessing and feature extraction using TF-IDF
2. Train-test split with stratification
3. Model training with cross-validation
4. Performance evaluation and model selection
5. Best model selection based on accuracy

### Topic Modeling Algorithms

#### Latent Dirichlet Allocation (LDA)
LDA is a generative probabilistic model that assumes documents are mixtures of topics:
- Discovers hidden topic structure in document collections
- Provides topic-word and document-topic probability distributions
- Suitable for interpretable topic discovery
- Works well with count-based features

**Key Parameters:**
- `n_components`: Number of topics to extract
- `max_iter`: Maximum number of iterations
- `learning_method`: Online or batch learning

#### Non-negative Matrix Factorization (NMF)
NMF factorizes the document-term matrix into topic and word matrices:
- Produces more coherent and interpretable topics
- Works well with TF-IDF features
- Faster convergence than LDA
- Good for sparse data

**Key Parameters:**
- `n_components`: Number of topics
- `alpha`: Regularization parameter
- `l1_ratio`: L1/L2 regularization mix

#### K-means Clustering
K-means groups similar documents into clusters that represent topics:
- Fast and scalable algorithm
- Works well with TF-IDF features
- Provides hard cluster assignments
- Good for large datasets

**Key Parameters:**
- `n_clusters`: Number of clusters/topics
- `max_iter`: Maximum iterations
- `n_init`: Number of random initializations

### Categorization Models

#### Rule-Based Categorization
Uses predefined keyword dictionaries for each category:
- Fast and interpretable
- No training data required
- Easy to customize and update
- Good baseline performance

**Categories and Keywords:**
- **Product Quality**: quality, defective, durable, material, build
- **Customer Service**: service, support, staff, helpful, response
- **Pricing**: price, expensive, affordable, value, cost
- **Delivery/Shipping**: delivery, shipping, fast, delayed, packaging
- **Website/UI**: website, navigation, interface, loading, mobile
- **General**: overall, experience, satisfied, recommend

#### Machine Learning Categorization
Trains supervised models on labeled feedback data:
- Higher accuracy with sufficient training data
- Learns complex patterns and relationships
- Adapts to domain-specific language
- Provides confidence scores

#### Ensemble Approach
Combines rule-based and ML methods:
- Leverages strengths of both approaches
- More robust predictions
- Configurable weighting between methods
- Fallback to rule-based when ML unavailable

### Model Performance and Evaluation

The system provides comprehensive model evaluation metrics:

**Classification Metrics:**
- Accuracy: Overall correctness of predictions
- Precision: True positives / (True positives + False positives)
- Recall: True positives / (True positives + False negatives)
- F1-Score: Harmonic mean of precision and recall

**Topic Modeling Metrics:**
- Perplexity: Measure of how well model predicts sample (LDA)
- Coherence: Semantic similarity of topic words
- Silhouette Score: Cluster quality measure (K-means)

**Model Selection:**
- Cross-validation for robust performance estimation
- Automatic best model selection based on validation metrics
- Model persistence for deployment consistency
- Regular retraining capabilities

### Feature Engineering

**Text Features:**
- TF-IDF vectors with n-gram support (1-2 grams)
- Character and word count statistics
- Punctuation and capitalization analysis
- Part-of-speech tag distributions
- Named entity recognition features

**Preprocessing Pipeline:**
- Text cleaning and normalization
- Stopword removal with custom lists
- Lemmatization and stemming options
- Feature scaling and selection
- Dimensionality reduction when needed

## Docker Deployment

The system is designed for easy deployment using Docker and Docker Compose, supporting both development and production environments.

### Container Architecture

The Docker setup includes multiple services:

**Main Application Container (`feedback-api`)**
- Python 3.11 slim base image
- All dependencies pre-installed
- NLTK data downloaded during build
- Non-root user for security
- Health checks configured
- Volume mounts for data persistence

**Redis Container (`redis`)**
- Used for caching and session storage
- Persistent data storage
- Health monitoring
- Alpine Linux for minimal footprint

**PostgreSQL Container (`postgres`)**
- Persistent database storage
- Automated initialization scripts
- Health checks and monitoring
- Configurable credentials

**Nginx Container (`nginx`) - Production Profile**
- Reverse proxy and load balancer
- SSL/TLS termination
- Static file serving
- Rate limiting and security headers

**Monitoring Stack - Monitoring Profile**
- Prometheus for metrics collection
- Grafana for visualization and dashboards
- Persistent data storage
- Pre-configured dashboards

### Deployment Profiles

**Development Profile (Default)**
```bash
docker-compose up -d
```
Includes: API, Redis, PostgreSQL

**Production Profile**
```bash
docker-compose --profile production up -d
```
Includes: All services + Nginx reverse proxy

**Monitoring Profile**
```bash
docker-compose --profile monitoring up -d
```
Includes: All services + Prometheus + Grafana

### Environment Configuration

**Development Environment:**
- Debug mode enabled
- Detailed logging
- Hot reloading (with volume mounts)
- Development database settings

**Production Environment:**
- Optimized for performance
- Security hardening
- Resource limits
- Production logging configuration
- SSL/TLS encryption

### Scaling and High Availability

**Horizontal Scaling:**
```bash
docker-compose up -d --scale feedback-api=3
```

**Load Balancing:**
- Nginx upstream configuration
- Health check integration
- Session affinity options
- Failover capabilities

**Data Persistence:**
- Named volumes for database data
- Model and log persistence
- Backup and restore procedures
- Data migration support

### Monitoring and Logging

**Health Checks:**
- Application health endpoint
- Database connectivity checks
- Redis availability monitoring
- Automatic container restart

**Logging:**
- Centralized log collection
- Structured JSON logging
- Log rotation and retention
- Error alerting integration

**Metrics:**
- Application performance metrics
- System resource monitoring
- Custom business metrics
- Real-time dashboards

### Security Considerations

**Container Security:**
- Non-root user execution
- Minimal base images
- Regular security updates
- Vulnerability scanning

**Network Security:**
- Internal network isolation
- Exposed ports minimization
- SSL/TLS encryption
- Rate limiting and DDoS protection

**Data Security:**
- Environment variable secrets
- Database encryption
- Secure credential management
- Access control and authentication

### Deployment Commands

**Basic Deployment:**
```bash
# Clone repository
git clone <repository-url>
cd AI-Powered-Customer-Feedback-Analysis-System

# Start services
docker-compose up -d

# View logs
docker-compose logs -f

# Stop services
docker-compose down
```

**Production Deployment:**
```bash
# Set production environment
export COMPOSE_PROFILES=production

# Deploy with production configuration
docker-compose up -d

# Monitor deployment
docker-compose ps
docker-compose logs -f feedback-api
```

**Maintenance Operations:**
```bash
# Update application
docker-compose pull
docker-compose up -d

# Backup data
docker-compose exec postgres pg_dump -U feedback_user feedback_analysis > backup.sql

# Scale services
docker-compose up -d --scale feedback-api=3

# View resource usage
docker stats
```



## Development

This section provides guidance for developers who want to contribute to or extend the AI-Powered Customer Feedback Analysis System.

### Development Environment Setup

**Prerequisites:**
- Python 3.11+
- Git
- Virtual environment tool (venv, conda, or virtualenv)
- Code editor (VS Code, PyCharm, etc.)

**Setup Steps:**
```bash
# Clone the repository
git clone <repository-url>
cd AI-Powered-Customer-Feedback-Analysis-System

# Create and activate virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install development dependencies
pip install -r requirements.txt
pip install -e .  # Install in development mode

# Install pre-commit hooks (optional)
pip install pre-commit
pre-commit install
```

### Code Structure and Standards

**Code Organization:**
- `src/`: Main application code
- `tests/`: Unit and integration tests
- `docs/`: Documentation files
- `scripts/`: Utility scripts
- `config/`: Configuration files

**Coding Standards:**
- Follow PEP 8 style guidelines
- Use type hints for function parameters and return values
- Write comprehensive docstrings for all functions and classes
- Maintain test coverage above 80%
- Use meaningful variable and function names

**Code Formatting:**
```bash
# Format code with Black
black src/ tests/

# Check code style with flake8
flake8 src/ tests/

# Sort imports with isort
isort src/ tests/
```

### Adding New Features

**Sentiment Analysis Extensions:**
To add a new sentiment analysis model:

1. Create a new method in `SentimentAnalyzer` class
2. Follow the existing method signature pattern
3. Add model configuration to `config.ini`
4. Update the ensemble method if needed
5. Add comprehensive tests

Example:
```python
def analyze_sentiment_custom(self, text: str) -> Dict[str, Union[str, float, Dict]]:
    """
    Analyze sentiment using custom model.
    
    Args:
        text (str): Text to analyze
        
    Returns:
        Dict: Sentiment analysis results
    """
    # Implementation here
    pass
```

**Topic Modeling Extensions:**
To add a new topic modeling algorithm:

1. Implement the algorithm in `TopicModeler` class
2. Follow the naming convention: `fit_<algorithm>_model`
3. Add topic extraction method: `_extract_<algorithm>_topics`
4. Update `fit_all_models` method
5. Add configuration parameters

**Categorization Extensions:**
To add new categories or improve categorization:

1. Update category keywords in `_initialize_category_keywords`
2. Add new categories to default list
3. Update rule-based logic if needed
4. Retrain ML models with new categories
5. Update API documentation

### Testing

The project uses pytest for testing with comprehensive test coverage.

**Running Tests:**
```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=src --cov-report=html

# Run specific test file
pytest tests/test_sentiment_analysis.py

# Run with verbose output
pytest -v

# Run tests in parallel
pytest -n auto
```

**Test Categories:**

**Unit Tests:**
- Test individual functions and methods
- Mock external dependencies
- Fast execution
- High coverage of edge cases

**Integration Tests:**
- Test component interactions
- Use real dependencies where appropriate
- Test API endpoints
- Validate data flow

**Performance Tests:**
- Measure execution time
- Memory usage profiling
- Load testing for API endpoints
- Scalability validation

**Writing Tests:**
```python
import pytest
from src.sentiment_analysis import SentimentAnalyzer

class TestSentimentAnalyzer:
    def setup_method(self):
        """Setup test fixtures."""
        self.analyzer = SentimentAnalyzer(model_type='lexicon')
    
    def test_positive_sentiment(self):
        """Test positive sentiment detection."""
        result = self.analyzer.analyze_sentiment_lexicon("I love this product!")
        assert result['sentiment'] == 'positive'
        assert result['confidence'] > 0.5
    
    def test_empty_text(self):
        """Test handling of empty text."""
        result = self.analyzer.analyze_sentiment_lexicon("")
        assert result['sentiment'] == 'neutral'
        assert result['confidence'] == 0.0
```

### API Development

**Adding New Endpoints:**
1. Define the endpoint in `api.py`
2. Follow RESTful conventions
3. Add input validation
4. Implement error handling
5. Add comprehensive documentation
6. Write integration tests

**Example Endpoint:**
```python
@app.route('/feedback/analyze', methods=['POST'])
def analyze_feedback():
    """
    Analyze feedback using all available models.
    
    Returns:
        JSON response with analysis results
    """
    try:
        data = request.get_json()
        
        if not data or 'feedback_text' not in data:
            return jsonify({'error': 'feedback_text is required'}), 400
        
        # Implementation here
        
        return jsonify(results)
        
    except Exception as e:
        logger.error(f"Error analyzing feedback: {str(e)}")
        return jsonify({'error': 'Internal server error'}), 500
```

### Performance Optimization

**Profiling:**
```bash
# Profile API performance
python -m cProfile -o profile_output.prof src/api.py

# Analyze profile results
python -c "import pstats; pstats.Stats('profile_output.prof').sort_stats('cumulative').print_stats(20)"
```

**Optimization Strategies:**
- Implement caching for expensive operations
- Use batch processing for multiple items
- Optimize database queries
- Implement connection pooling
- Use asynchronous processing where appropriate

**Memory Management:**
- Monitor memory usage during processing
- Implement garbage collection for large datasets
- Use generators for streaming data
- Optimize model loading and storage

### Database Integration

**Adding Database Support:**
The system is designed to support database integration for persistent storage.

**Recommended Approach:**
1. Use SQLAlchemy for ORM
2. Implement repository pattern
3. Add database migrations
4. Update configuration
5. Add database tests

**Example Model:**
```python
from sqlalchemy import Column, Integer, String, DateTime, Text, Float
from sqlalchemy.ext.declarative import declarative_base

Base = declarative_base()

class Feedback(Base):
    __tablename__ = 'feedback'
    
    id = Column(Integer, primary_key=True)
    feedback_text = Column(Text, nullable=False)
    rating = Column(Integer)
    customer_id = Column(String(100))
    product_id = Column(String(100))
    sentiment = Column(String(20))
    sentiment_confidence = Column(Float)
    category = Column(String(50))
    created_at = Column(DateTime)
    updated_at = Column(DateTime)
```

### Deployment and DevOps

**CI/CD Pipeline:**
```yaml
# Example GitHub Actions workflow
name: CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: 3.11
    - name: Install dependencies
      run: |
        pip install -r requirements.txt
    - name: Run tests
      run: |
        pytest --cov=src --cov-report=xml
    - name: Upload coverage
      uses: codecov/codecov-action@v1
```

**Environment Management:**
- Use environment-specific configuration files
- Implement feature flags for gradual rollouts
- Monitor application performance and errors
- Set up automated backups and disaster recovery

## Testing

Comprehensive testing ensures the reliability and accuracy of the AI-Powered Customer Feedback Analysis System.

### Test Framework

The project uses **pytest** as the primary testing framework, chosen for its:
- Simple and readable test syntax
- Powerful fixtures and parametrization
- Extensive plugin ecosystem
- Excellent coverage reporting
- Integration with CI/CD pipelines

### Test Structure

```
tests/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ conftest.py                 # Shared fixtures and configuration
â”œâ”€â”€ unit/                       # Unit tests
â”‚   â”œâ”€â”€ test_data_ingestion.py
â”‚   â”œâ”€â”€ test_preprocessing.py
â”‚   â”œâ”€â”€ test_sentiment_analysis.py
â”‚   â”œâ”€â”€ test_topic_modeling.py
â”‚   â””â”€â”€ test_categorization.py
â”œâ”€â”€ integration/                # Integration tests
â”‚   â”œâ”€â”€ test_api_endpoints.py
â”‚   â”œâ”€â”€ test_model_pipeline.py
â”‚   â””â”€â”€ test_data_flow.py
â”œâ”€â”€ performance/                # Performance tests
â”‚   â”œâ”€â”€ test_api_performance.py
â”‚   â””â”€â”€ test_model_performance.py
â””â”€â”€ fixtures/                   # Test data and fixtures
    â”œâ”€â”€ sample_feedback.csv
    â”œâ”€â”€ sample_feedback.json
    â””â”€â”€ test_models/
```

### Running Tests

**Basic Test Execution:**
```bash
# Run all tests
pytest

# Run with verbose output
pytest -v

# Run specific test file
pytest tests/unit/test_sentiment_analysis.py

# Run specific test method
pytest tests/unit/test_sentiment_analysis.py::TestSentimentAnalyzer::test_positive_sentiment
```

**Coverage Testing:**
```bash
# Run tests with coverage
pytest --cov=src

# Generate HTML coverage report
pytest --cov=src --cov-report=html

# Generate XML coverage report (for CI)
pytest --cov=src --cov-report=xml

# Set minimum coverage threshold
pytest --cov=src --cov-fail-under=80
```

**Parallel Testing:**
```bash
# Run tests in parallel (requires pytest-xdist)
pip install pytest-xdist
pytest -n auto

# Run with specific number of workers
pytest -n 4
```

### Test Categories

**Unit Tests:**
Test individual components in isolation with mocked dependencies.

```python
# Example unit test
import pytest
from unittest.mock import Mock, patch
from src.sentiment_analysis import SentimentAnalyzer

class TestSentimentAnalyzer:
    def setup_method(self):
        self.analyzer = SentimentAnalyzer(model_type='lexicon')
    
    def test_positive_sentiment_detection(self):
        """Test detection of positive sentiment."""
        result = self.analyzer.analyze_sentiment_lexicon("I love this product!")
        
        assert result['sentiment'] == 'positive'
        assert result['confidence'] > 0.5
        assert 'scores' in result
    
    @pytest.mark.parametrize("text,expected", [
        ("Great product!", "positive"),
        ("Terrible service!", "negative"),
        ("It's okay.", "neutral"),
    ])
    def test_sentiment_classification(self, text, expected):
        """Test sentiment classification with various inputs."""
        result = self.analyzer.analyze_sentiment_lexicon(text)
        assert result['sentiment'] == expected
```

**Integration Tests:**
Test interactions between components and external systems.

```python
# Example integration test
import pytest
import requests
from src.api import app

class TestAPIIntegration:
    def setup_method(self):
        self.client = app.test_client()
        app.config['TESTING'] = True
    
    def test_feedback_submission_flow(self):
        """Test complete feedback submission and analysis flow."""
        # Submit feedback
        response = self.client.post('/feedback/submit', json={
            'feedback_text': 'Great product quality!',
            'rating': 5
        })
        
        assert response.status_code == 201
        data = response.get_json()
        feedback_id = data['feedback_id']
        
        # Preprocess feedback
        response = self.client.post('/feedback/preprocess', json={
            'feedback_ids': [feedback_id]
        })
        
        assert response.status_code == 200
        
        # Retrieve processed feedback
        response = self.client.get(f'/feedback/{feedback_id}')
        
        assert response.status_code == 200
        data = response.get_json()
        assert 'processed_text' in data
```

**Performance Tests:**
Measure and validate system performance under various conditions.

```python
# Example performance test
import pytest
import time
from src.sentiment_analysis import SentimentAnalyzer

class TestPerformance:
    def setup_method(self):
        self.analyzer = SentimentAnalyzer(model_type='lexicon')
        self.sample_texts = ["Sample text"] * 1000
    
    def test_batch_processing_performance(self):
        """Test performance of batch sentiment analysis."""
        start_time = time.time()
        
        results = self.analyzer.analyze_batch(self.sample_texts)
        
        end_time = time.time()
        processing_time = end_time - start_time
        
        # Should process 1000 texts in under 10 seconds
        assert processing_time < 10.0
        assert len(results) == 1000
        
        # Calculate throughput
        throughput = len(self.sample_texts) / processing_time
        print(f"Throughput: {throughput:.2f} texts/second")
```

### Test Data Management

**Fixtures:**
```python
# conftest.py
import pytest
import pandas as pd
from src.data_ingestion import FeedbackDataIngestion

@pytest.fixture
def sample_feedback_data():
    """Provide sample feedback data for testing."""
    return pd.DataFrame({
        'feedback_text': [
            'Great product!',
            'Poor service.',
            'Average quality.'
        ],
        'rating': [5, 1, 3],
        'customer_id': ['c1', 'c2', 'c3']
    })

@pytest.fixture
def feedback_ingestion():
    """Provide configured FeedbackDataIngestion instance."""
    return FeedbackDataIngestion()
```

**Test Data Files:**
- `fixtures/sample_feedback.csv`: Sample CSV data
- `fixtures/sample_feedback.json`: Sample JSON data
- `fixtures/test_models/`: Pre-trained test models

### Continuous Integration

**GitHub Actions Configuration:**
```yaml
name: Test Suite

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

jobs:
  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: [3.9, 3.10, 3.11]
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v3
      with:
        python-version: ${{ matrix.python-version }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-cov pytest-xdist
    
    - name: Download NLTK data
      run: |
        python -c "import nltk; nltk.download('punkt'); nltk.download('stopwords'); nltk.download('wordnet'); nltk.download('vader_lexicon')"
    
    - name: Run tests
      run: |
        pytest --cov=src --cov-report=xml --cov-report=html -n auto
    
    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        flags: unittests
        name: codecov-umbrella
```

### Test Best Practices

**Writing Effective Tests:**
1. **Test Naming**: Use descriptive names that explain what is being tested
2. **Test Structure**: Follow Arrange-Act-Assert pattern
3. **Independence**: Tests should not depend on each other
4. **Deterministic**: Tests should produce consistent results
5. **Fast Execution**: Keep tests fast for quick feedback

**Mocking Guidelines:**
```python
from unittest.mock import Mock, patch

# Mock external dependencies
@patch('src.sentiment_analysis.nltk.download')
def test_nltk_download_called(mock_download):
    analyzer = SentimentAnalyzer()
    mock_download.assert_called()

# Mock expensive operations
@patch('src.topic_modeling.TopicModeler.fit_lda_model')
def test_topic_modeling_with_mock(mock_fit_lda):
    mock_fit_lda.return_value = {'topics': []}
    modeler = TopicModeler()
    result = modeler.fit_all_models(['sample text'])
    assert 'lda' in result
```

## Contributing

We welcome contributions to the AI-Powered Customer Feedback Analysis System! This section provides guidelines for contributing to the project.

### How to Contribute

**Types of Contributions:**
- Bug reports and fixes
- Feature requests and implementations
- Documentation improvements
- Performance optimizations
- Test coverage improvements
- Code quality enhancements

### Getting Started

1. **Fork the Repository**
   ```bash
   # Fork on GitHub, then clone your fork
   git clone https://github.com/yourusername/AI-Powered-Customer-Feedback-Analysis-System.git
   cd AI-Powered-Customer-Feedback-Analysis-System
   ```

2. **Set Up Development Environment**
   ```bash
   # Create virtual environment
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   
   # Install dependencies
   pip install -r requirements.txt
   pip install -e .
   
   # Install development tools
   pip install black flake8 isort pre-commit pytest pytest-cov
   
   # Set up pre-commit hooks
   pre-commit install
   ```

3. **Create a Feature Branch**
   ```bash
   git checkout -b feature/your-feature-name
   # or
   git checkout -b bugfix/your-bug-description
   ```

### Development Workflow

1. **Make Your Changes**
   - Write clean, well-documented code
   - Follow existing code style and patterns
   - Add tests for new functionality
   - Update documentation as needed

2. **Test Your Changes**
   ```bash
   # Run tests
   pytest
   
   # Check coverage
   pytest --cov=src --cov-report=html
   
   # Format code
   black src/ tests/
   isort src/ tests/
   
   # Check code style
   flake8 src/ tests/
   ```

3. **Commit Your Changes**
   ```bash
   git add .
   git commit -m "feat: add new sentiment analysis model"
   ```

4. **Push and Create Pull Request**
   ```bash
   git push origin feature/your-feature-name
   ```
   Then create a pull request on GitHub.

### Contribution Guidelines

**Code Style:**
- Follow PEP 8 style guidelines
- Use Black for code formatting
- Use isort for import sorting
- Maximum line length: 88 characters
- Use meaningful variable and function names

**Documentation:**
- Write comprehensive docstrings for all functions and classes
- Update README.md for significant changes
- Add inline comments for complex logic
- Include examples in docstrings

**Testing:**
- Write tests for all new functionality
- Maintain test coverage above 80%
- Include both positive and negative test cases
- Test edge cases and error conditions

**Commit Messages:**
Follow conventional commit format:
```
type(scope): description

[optional body]

[optional footer]
```

Types: feat, fix, docs, style, refactor, test, chore

Examples:
- `feat(sentiment): add BERT-based sentiment analysis`
- `fix(api): handle empty feedback text properly`
- `docs(readme): update installation instructions`

### Pull Request Process

1. **Before Submitting:**
   - Ensure all tests pass
   - Update documentation
   - Add changelog entry if applicable
   - Rebase on latest main branch

2. **Pull Request Description:**
   - Clearly describe the changes
   - Reference related issues
   - Include screenshots for UI changes
   - List breaking changes if any

3. **Review Process:**
   - Maintainers will review your PR
   - Address feedback and requested changes
   - Ensure CI/CD pipeline passes
   - Squash commits if requested

### Issue Reporting

**Bug Reports:**
Include the following information:
- Clear description of the bug
- Steps to reproduce
- Expected vs actual behavior
- Environment details (OS, Python version, etc.)
- Error messages and stack traces
- Minimal code example if applicable

**Feature Requests:**
Include the following information:
- Clear description of the feature
- Use case and motivation
- Proposed implementation approach
- Potential impact on existing functionality
- Alternative solutions considered

### Code of Conduct

We are committed to providing a welcoming and inclusive environment for all contributors. Please:

- Be respectful and constructive in discussions
- Welcome newcomers and help them get started
- Focus on what is best for the community
- Show empathy towards other community members
- Respect differing viewpoints and experiences

### Recognition

Contributors will be recognized in:
- CONTRIBUTORS.md file
- Release notes for significant contributions
- GitHub contributor statistics
- Project documentation acknowledgments

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

### MIT License Summary

The MIT License is a permissive open-source license that allows you to:

**Permissions:**
- âœ… Commercial use
- âœ… Modification
- âœ… Distribution
- âœ… Private use

**Conditions:**
- ðŸ“„ License and copyright notice must be included

**Limitations:**
- âŒ No liability
- âŒ No warranty

### Full License Text

```
MIT License

Copyright (c) 2024 AI-Powered Customer Feedback Analysis System Contributors

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
```

### Third-Party Licenses

This project uses several third-party libraries, each with their own licenses:

- **Flask**: BSD-3-Clause License
- **scikit-learn**: BSD-3-Clause License
- **pandas**: BSD-3-Clause License
- **NumPy**: BSD-3-Clause License
- **NLTK**: Apache License 2.0
- **Redis**: BSD-3-Clause License
- **PostgreSQL**: PostgreSQL License

All third-party licenses are compatible with the MIT License and allow for commercial and non-commercial use.

---

## Support and Contact

For questions, issues, or contributions:

- **GitHub Issues**: [Create an issue](https://github.com/yourusername/AI-Powered-Customer-Feedback-Analysis-System/issues)
- **Documentation**: [Project Wiki](https://github.com/yourusername/AI-Powered-Customer-Feedback-Analysis-System/wiki)
- **Discussions**: [GitHub Discussions](https://github.com/yourusername/AI-Powered-Customer-Feedback-Analysis-System/discussions)

**Maintainers:**
- Primary Maintainer: [Your Name](mailto:your.email@example.com)
- Contributors: See [CONTRIBUTORS.md](CONTRIBUTORS.md)

---

**Built with â¤ï¸ by the AI-Powered Customer Feedback Analysis System Team**

